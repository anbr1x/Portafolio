{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ec92427-0f07-4a68-96bb-6c7f81b84fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Actu_Colums as Ac\n",
    "import win32com.client as win32\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.worksheet.table import Table, TableStyleInfo\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import pyxlsb\n",
    "import tqdm\n",
    "from typing import Optional\n",
    "from collections import defaultdict\n",
    "from babel.dates import format_date, format_datetime, Locale\n",
    "import pickle\n",
    "import calendar\n",
    "import locale\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b00c09-e6ba-4670-814a-2705d2370cf6",
   "metadata": {},
   "source": [
    "### El flujo de actualizacion es el siguiente : \n",
    "    -01.Tomo toda el reporte de PREPA\n",
    "    -02.Actualizo info del PAP(Seudo-Merge)\n",
    "    -03.Fill DATA y agrego antiguacion a los sin registrar\n",
    "    -04.Mapeo para crear las nuevas etapas\n",
    "    -05.To CSV (Capa plata)\n",
    "    -06.Agrupo y Comparo para crear medida de diferencia (Capa Gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c81cc8-62c2-4064-94d5-4de1208fb7b8",
   "metadata": {},
   "source": [
    "# Funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2fa06c9c-7918-4600-9622-c6205ff2094e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoy es: 30-07-2024\n"
     ]
    }
   ],
   "source": [
    "Today_str = datetime.date.today().strftime('%d-%m-%Y')\n",
    "Today_D_M = Today_str[0:5]\n",
    "Today_D_M = [Today_D_M[0:2],'.',Today_D_M[3:6]]\n",
    "Today_D_M = ''.join(Today_D_M)\n",
    "#Today_D_M = '06.02'\n",
    "print('Hoy es:',Today_str)\n",
    "\n",
    "def transformar_name(valor):\n",
    "    valor = str(valor)\n",
    "    if valor.isupper():\n",
    "        return valor\n",
    "    else:\n",
    "        try:\n",
    "            palabras = valor.split()\n",
    "            frase = ' '.join([palabras[0], palabras[2]])\n",
    "            return frase\n",
    "        except:\n",
    "            return valor\n",
    "        \n",
    "def process_df(df: pd.DataFrame,clases_unicas: list,index=['NOMPROVEEDOR']):\n",
    "    \"\"\" La funcion recibe un df, y las clases unicas\n",
    "        Y devuelve el df uniformizado para cada clase\n",
    "        Llena los valores faltantes con 0\"\"\"\n",
    "    pivot_table = pd.pivot_table(df, values='PEND_FACT_SOLES', index=index+['ESTADO'], aggfunc=pd.Series.sum) #Agrupo \n",
    "    grupos = pivot_table.groupby(index) #creo un data frame para cada contrata\n",
    "    # Para cada grupo, crea un nuevo dataframe y guárdalo en un diccionario\n",
    "    dataframes = {}\n",
    "    for nombre, datos in grupos: # Creo los df dentro del dic\n",
    "        dataframes[nombre] = datos\n",
    "    for key in dataframes.keys(): # para cada df en el dic\n",
    "        df = dataframes[key].reset_index()\n",
    "        ##display(df)\n",
    "        #display(clases_unicas)\n",
    "        df1 = df.set_index('ESTADO').reindex(clases_unicas).reset_index() #normalizo, creando filas para todos los ESTADOS\n",
    "        df1.RESPONSABLE2 = key[0]\n",
    "        df1.NOMPROVEEDOR = key[1]  #Relleno los NAN  #Relleno los NAN\n",
    "        df1 = df1.fillna(0)  \n",
    "        dataframes[key] = df1   #Reescribo los Df para cada clave\n",
    "    df_concat = pd.concat(dataframes.values(),ignore_index=True) # Compacto todo los df del dic en uno grande \n",
    "    pivot_table_1 = pd.pivot_table(df_concat, values='PEND_FACT_SOLES', index= index+['ESTADO'] , aggfunc=pd.Series.sum) #agrupo de nuevo\n",
    "    return pivot_table_1\n",
    "\n",
    "def calc_diff(df1: pd.DataFrame,df2: pd.DataFrame, index= ['NOMPROVEEDOR', 'ESTADO']) -> pd.DataFrame:\n",
    "    \"\"\" entran 2 dataframes , los proceso , y en base a los df procesados \n",
    "        calculo la diferencia en una nueva columna, \n",
    "        y añado esta columna de diferencia al df actual,\n",
    "        DF1 - DF2\"\"\"\n",
    "    clases_unicas = pd.concat([df1['ESTADO'], df2['ESTADO']]).unique() #Creo listas de claves unicas\n",
    "    df1_proces = process_df(df1,clases_unicas,index)\n",
    "    df2_proces = process_df(df2,clases_unicas,index)\n",
    "    \n",
    "    df_diff = df1_proces - df2_proces\n",
    "    diff_pivot_table_reset = df_diff.reset_index()\n",
    "    diff_pivot_table_reset.rename(columns={'PEND_FACT_SOLES': 'DIFERENCIA EN SOLES'}, inplace=True)\n",
    "    # Merge diff_pivot_table_filled_reset con PrePa_O_EI\n",
    "    PrePa_O_EI = pd.merge(df1, diff_pivot_table_reset, on=index+['ESTADO'],how='left')    \n",
    "    return PrePa_O_EI\n",
    "    \n",
    "def new_line_TS(df : pd.DataFrame,ruta_del_csv : str,Fecha: str,index:list): \n",
    "    df['TIME'] = Fecha\n",
    "    pivot_table = pd.pivot_table(df, values='PEND_FACT_SOLES', index=index, aggfunc=pd.Series.sum) #Agrupo \n",
    "    df_reset = pivot_table.reset_index(drop=False)\n",
    "    #convetir la columna del agrupado al formato d efehca \n",
    "    # Convierte la columna 'Fecha' a datetime\n",
    "    df_reset['TIME'] = pd.to_datetime(df_reset['TIME'],format = '%d-%m-%Y')\n",
    "    \n",
    "    # Formatea la columna 'Fecha'\n",
    "    df_reset['TIME Format'] = df_reset['TIME'].apply(lambda x: format_date(x, 'EEE dd-MM-yyyy', locale=Locale('es', 'ES')))\n",
    "    df_reset.to_csv(ruta_del_csv, mode='a', header=False,index=False)\n",
    "    \n",
    "\n",
    "# Definimos los valores que estamos buscando en una lista\n",
    "def map_estados(PRE_all_act:pd.DataFrame):\n",
    "    PRE_all_act.loc[PRE_all_act['ESTADO_PAP'].isna(), 'ESTADO_PAP'] = 'Sin Registrar' #Reemplazo valor para determinada condicion \n",
    "    \n",
    "    PRE_all_act['RESPONSABLE_PAP'] = PRE_all_act['RESPONSABLE_PAP'].replace('nan','SIN RESPONSABLE')\n",
    "    PRE_all_act['RESPONSABLE_PAP'] = PRE_all_act['RESPONSABLE_PAP'].replace('','SIN RESPONSABLE')\n",
    "    PRE_all_act['RESPONSABLE_PAP'] = PRE_all_act['RESPONSABLE_PAP'].replace('Luis Romero','Luis - Romero')## valor atipico\n",
    "    \n",
    "    # Aplicar la transformación\n",
    "    PRE_all_act['RESPONSABLE_PAP'] = PRE_all_act['RESPONSABLE_PAP'].apply(transformar_name)    \n",
    "    valores_buscados = ['Aprobaciones FAC', 'Aprobaciones PAC']\n",
    "    \n",
    "    # Creamos la nueva columna basada en la condición\n",
    "    PRE_all_act['ESTADO'] = np.where(PRE_all_act['ESTADO_PAP'].isin(valores_buscados), \n",
    "                                     PRE_all_act['RESPONSABLE_PAP'], \n",
    "                                     PRE_all_act['ESTADO_PAP'])\n",
    " \n",
    "    map_estado = {'Auto ATP' : 'Registrar lista de pendientes',\n",
    "           'Visita ejecutada' : 'Registrar lista de pendientes',\n",
    "            'Programado' : 'En ATP',\n",
    "            'FAC' : 'Solic FAC',\n",
    "            'PAC': 'Solic PAC',\n",
    "            'Programación ATP':'Programar ATP',\n",
    "            'Registrado':'Programar ATP','Lista Pendientes':'Validar PL.'}\n",
    "    PRE_all_act.loc[PRE_all_act['ESTADO'] == 'SIN RESPONSABLE', 'ESTADO'] = 'Por Asignar'\n",
    "    PRE_all_act['ESTADO'] = PRE_all_act['ESTADO'].replace(map_estado)\n",
    "    return PRE_all_act\n",
    "    \n",
    "def update_from_PAP(Prepa_PR:pd.DataFrame,PAP_S:pd.DataFrame):\n",
    "    unhavent_columns = set(PAP_S.columns.tolist()) - set(Prepa_PR.columns.tolist()) # Columnas que le faltan al grande del chico\n",
    "    # Crear un nuevo DataFrame con las columnas necesarias\n",
    "    new_columns = pd.DataFrame(index=Prepa_PR.index, columns=list(unhavent_columns), dtype='object')\n",
    "    \n",
    "    # Concatenar el nuevo DataFrame con el original\n",
    "    Prepa_PR = pd.concat([Prepa_PR, new_columns], axis=1)\n",
    "    PRE_all_act =  Ac.update_values_optimized_V2(Prepa_PR, PAP_S, \"OC Posición\",['PAP','SITE','ID Site','ESTADO_PAP','F.Creación',\n",
    "                                                'RESPONSABLE_PAP','ANTIGUAMIENTO_PAP','Gerencia','F.Modifica']) \n",
    "    duplicated_index = PRE_all_act.index.duplicated(keep=False)\n",
    "    df_duplicated = PRE_all_act[duplicated_index].copy()\n",
    "    PRE_all_act.drop(PRE_all_act[duplicated_index].index, inplace=True) ## dropeo las duplicadas\n",
    "    # Ordena el DataFrame por la columna de fechas  LA FECHA DE CREACION ME SIRVE PARA ELMINAR DUPLICADOS\n",
    "    df_duplicated['F.Modifica'] = pd.to_datetime(df_duplicated['F.Modifica'], format=\"%d/%m/%Y %I:%M:%S %p\") # Paso a fecha para ordenar\n",
    "    df_duplicated.sort_values('F.Modifica', inplace=True)\n",
    "    df_duplicated_NR = df_duplicated[df_duplicated.ESTADO_PAP != 'Rechazado'].sort_index(ascending=False)\n",
    "    df_duplicated_NRF = df_duplicated_NR.loc[~df_duplicated_NR.index.duplicated(keep='first')]\n",
    "    #df_duplicated['F.Creación'] = df_duplicated['F.Creación'].dt.strftime(\"%m/%d/%Y %I:%M:%S %p\") # Regreso a str \n",
    "    PRE_all_act = pd.concat([PRE_all_act, df_duplicated_NRF])\n",
    "    Cash_out = PRE_all_act.PEND_FACT_SOLES.sum()\n",
    "    PRE_all_act.RESPONSABLE_PAP = PRE_all_act.RESPONSABLE_PAP.astype(str)\n",
    "    return PRE_all_act\n",
    "\n",
    "def load_df_by_name(directorios:str, cadena:str) -> pd.DataFrame:\n",
    "    df_list = []\n",
    "    for dictory in directorios:\n",
    "        ruta = Ac.load_df_by_name(dictory, cadena)\n",
    "        try:\n",
    "            df = pd.read_excel(ruta, sheet_name='Hoja2')\n",
    "            #print('Machea con nombre de hoja2')\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}. Trying with 'Sheet1'\")\n",
    "            df = pd.read_excel(ruta, sheet_name='Sheet1')\n",
    "            #print('Machea con nombre de Sheet1')\n",
    "        print(ruta)\n",
    "        df_list.append(df)\n",
    "    return df_list\n",
    "\n",
    "def Merge_data(PAP:pd.DataFrame,Prepa:pd.DataFrame):\n",
    "    \"\"\"Toma un segmento del PAP,lo procesa. Procesa la base y hace un merge con el PAP,\n",
    "        Mapea los estados, dropea las filas de PENDIENTE en caso exista la columna STATUSFINAL\"\"\"\n",
    "####################Preproces PAP################################################\n",
    "    PAP_f = PAP[['OC Posición','N° Sol','Estado','Nombre responsable','Id.SIte',\n",
    "                 'SIte','# Días','F.Creación','Gerencia','F.Modifica']] ## Selecciona un Segmento de columnas del PAP \n",
    "\n",
    "    PAP_f = PAP_f.dropna(subset=['Id.SIte'])\n",
    "    PAP_f = PAP_f[PAP_f['# Días'] < 500]\n",
    "    \n",
    "    #PAP_f_N = PAP_f[PAP_f['Id.SIte'].str.startswith(('L','T','SAD','CL','CAC'))].copy()\n",
    "    PAP_f_N = PAP_f.rename(columns={'N° Sol': 'PAP', #Rename\n",
    "                                   'SIte': 'SITE',\n",
    "                                   'Estado': 'ESTADO_PAP',\n",
    "                                    '# Días': 'ANTIGUAMIENTO_PAP',\n",
    "                                    'Id.SIte': 'ID Site',\n",
    "                                 'Nombre responsable': 'RESPONSABLE_PAP' })\n",
    "    PAP_S = Ac.split_ocs(PAP_f_N) # Spliteo OCs    \n",
    "    PAP_S['OC Posición'] = PAP_S['OC Posición'].astype(str)\n",
    "###################Pre proces Prepa####################################################\n",
    "    Prepa_CI = Prepa[Prepa.SUB_DIRECCION == 'CONS E IMP']\n",
    "    Prepa_PR = Ac.convert_columns_to_str(Prepa_CI.copy(),['DOC_COMPRAS', 'POSIC','CONCA'])\n",
    "    Prepa_PR.loc[:, \"OC Posición\"] = Prepa_PR.loc[:, \"DOC_COMPRAS\"].str.cat(Prepa_PR.loc[:, \"POSIC\"], sep= \":\")\n",
    "    Monto_In = Prepa_PR[\"PEND_FACT_SOLES\"].sum() #Mont of USD \n",
    "    Prepa_PR = Prepa_PR.dropna(axis=1,how='all')\n",
    "########################### MERGE DATAFRAMES ###############################################\n",
    "    PRE_all_act = update_from_PAP(Prepa_PR,PAP_S)\n",
    "    Cash_out = PRE_all_act['PEND_FACT_SOLES'].sum()\n",
    "    print(Monto_In - Cash_out)    \n",
    "    PRE_all_act= map_estados(PRE_all_act)\n",
    "    try:\n",
    "        PRE_all_act = PRE_all_act[PRE_all_act[\"STATUSFINAL\"] == 'PENDIENTE']\n",
    "        print(\"Se encuentra la columan 'STATUSFINAL' y se dropeand las filas de mas\")\n",
    "    except:\n",
    "        pass        \n",
    "    return PRE_all_act    \n",
    "\n",
    "\n",
    "def find_ocs_sinSITE(df:pd.DataFrame):\n",
    "    list_of_OCs = df[df.SITE.isna()]['DOC_COMPRAS'].unique().tolist()\n",
    "    if not list_of_OCs:\n",
    "        print('No hay Filas sin SITE')\n",
    "    else:\n",
    "        resultado = [valor[4:] for valor in list_of_OCs] # Tomo los valores luego del 4500\n",
    "        a,b= Ac.MostCL_prefix(resultado)\n",
    "        print(\"Faltan: \",len(resultado),\" OCS\")\n",
    "        display(b)\n",
    "\n",
    "contrata_dic = {'DELTA ELECTRONICS (PERU) INC. S.R.L ELTEK PERU S.R.L.':'DELTA',\n",
    "                'COMUNICACION FUTURA SOCIEDAD ANONIM':'COMFUTURA'}\n",
    "columns_dic = {\"DOC COMPRAS\": \"Orden de Compra\" ,\n",
    "                \"NOMPROVEEDOR\" :\"CONTRATISTA\"\n",
    "               , \"PAP\":\"N° PAP\", \"PEND FACT SOLES\":\"PENDIENTE EN SOLES\"\n",
    "               , \"TEXTO BREVE\": \"DESCRIPCIÓN\"\n",
    "               , \"POSIC\":\"POSICIÓN\"\n",
    "               , \"ANTIGUAMIENTO PAP\" : \"ANTIGUAMIENTO PAP\"\n",
    "               , \"MES   COMPROMISO\" : \"MES DE COMPROMISO\"\n",
    "               , 'FECH CONTAB':'FECHA CONTABILIDAD'}\n",
    "\n",
    "def formated2bi(df_diff:pd.DataFrame,contrata_dic:dict=contrata_dic,columns_dic:dict=columns_dic):\n",
    "    def transformar_nombre(nombre):\n",
    "          nombre = nombre.upper()\n",
    "          nombre = nombre.replace('_', ' ')\n",
    "          nombre = nombre.replace('-', ' ')\n",
    "          return nombre\n",
    "\n",
    "    df_fomarted = df_diff.copy()\n",
    "    # Aplicar la función a los nombres de las columnas\n",
    "    df_fomarted.columns = map(transformar_nombre, df_fomarted.columns) # Normalizo nombres de columna\n",
    "    df_fomarted['SITE'] = df_fomarted['SITE'].str.replace('_', ' ')\n",
    "    df_fomarted['SITE'] = df_fomarted['SITE'].str.title()\n",
    "    df_fomarted['TEXTO BREVE'] = df_fomarted['TEXTO BREVE'].str.title()\n",
    "    #df_fomarted['NOMPROVEEDOR'].replace(contrata_dic,inplace=True)\n",
    "    df_fomarted['NOMPROVEEDOR'] = df_fomarted['NOMPROVEEDOR'].str.title()\n",
    "    \n",
    "    #Cambio los nombres de las columnas con un Map\n",
    "    df_fomarted.rename(columns=columns_dic, inplace=True)\n",
    "    #display(df_fomarted.info())\n",
    "    columns_2_drop = [\"EA EM\",\"PEND FACT\", \"CONCATENADO\",'TIPO MAT'\n",
    "                          , \"ELEMENTO PEP\",\"FONDO\",\"INDICADOR\", \"RESPONSABLE\", \"ANT PROYECTADO\",\"SUB DIRECCION\",\"DÍAS  2\"]\n",
    "    df_fomarted.drop(columns=columns_2_drop,inplace=True)\n",
    "    df_fomarted.columns = df_fomarted.columns.str.title()\n",
    "    return df_fomarted\n",
    "    \n",
    "def load_df_by_name(directorios:str, cadena:str) -> pd.DataFrame:\n",
    "    df_list = []\n",
    "    for dictory in directorios:\n",
    "        ruta = Ac.buscar_archivo_mas_antiguo(dictory, cadena)\n",
    "        try:\n",
    "            df = pd.read_excel(ruta, sheet_name='Hoja2')\n",
    "            #print('Machea con nombre de hoja2')\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}. Trying with 'Sheet1'\")\n",
    "            df = pd.read_excel(ruta, sheet_name='Sheet1')\n",
    "            #print('Machea con nombre de Sheet1')\n",
    "        #print(ruta)\n",
    "        df_list.append(df)\n",
    "    return df_list\n",
    "def get_recent_df(Carpeta_path: str,sheet_name='Hoja2',extension='.xlsx'):\n",
    "    \"\"\" Devuelve el df de la hoja especifica, del archivo mas reciente de la carpeta especificada\"\"\"\n",
    "    Path_n= Carpeta_path + '\\*'\n",
    "    tipo_de_archivo = f'*{extension}'\n",
    "    # Busca el archivo más reciente\n",
    "    archivos = glob.glob(Path_n + tipo_de_archivo)\n",
    "    archivo_mas_reciente = max(archivos, key=os.path.getctime)\n",
    "    nombre_del_archivo_N = os.path.basename(archivo_mas_reciente)\n",
    "    print(archivo_mas_reciente)\n",
    "    if extension == '.xlsx':\n",
    "        df = pd.read_excel(archivo_mas_reciente , sheet_name=sheet_name) \n",
    "    if extension == '.csv':\n",
    "        df = pd.read_csv(archivo_mas_reciente)\n",
    "    return df\n",
    "def cleanrows(df):\n",
    "    if 'STATUSFINAL' in df.columns:\n",
    "        df = df[df['STATUSFINAL'] == 'PENDIENTE']\n",
    "    elif 'STATUS FINAL' in df.columns:\n",
    "        df = df[df['STATUS FINAL'] == 'PENDIENTE']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6db1cb-bc65-4c78-8d8c-636313a4fcf6",
   "metadata": {},
   "source": [
    "## Cargo Prepa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6e9c6644-116b-4b80-b50b-4d6a1d9a1332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Scripts1/Code/ActPEA/archvis/Pre_pa/NEW\\7. Prepasivo completo (Finanzas Julio).xlsx\n"
     ]
    }
   ],
   "source": [
    "Path_n= 'D:/Scripts1/Code/ActPEA/archvis/Pre_pa/NEW/*'\n",
    "tipo_de_archivo = '*.xlsx'\n",
    "\n",
    "# Busca el archivo más reciente\n",
    "#archivos\n",
    "archivos = glob.glob(Path_n + tipo_de_archivo)\n",
    "archivo_mas_reciente = max(archivos, key=os.path.getctime)\n",
    "nombre_del_archivo_N = os.path.basename(archivo_mas_reciente)\n",
    "nombre_del_archivo_N\n",
    "Prepa_N = pd.read_excel(Path_n[0:-1] + nombre_del_archivo_N, sheet_name='DATA') \n",
    "print(archivo_mas_reciente)\n",
    "Prepa_N = cleanrows(Prepa_N)\n",
    "#aarchivos = glob.glob(Path_n + tipo_de_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8496770a-6838-460a-9707-6030a7863f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1242 entries, 1 to 1847\n",
      "Data columns (total 52 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   DOC_COMPRAS           1242 non-null   int64         \n",
      " 1   POSIC                 1242 non-null   int64         \n",
      " 2   CONCA                 1242 non-null   int64         \n",
      " 3   DOCUMENTO_REFERENCIA  1242 non-null   int64         \n",
      " 4   FONDO                 1242 non-null   object        \n",
      " 5   TIPO_MAT              1242 non-null   object        \n",
      " 6   TEXTO_BREVE           1242 non-null   object        \n",
      " 7   CODPROVEEDOR          1242 non-null   int64         \n",
      " 8   NOMPROVEEDOR          1242 non-null   object        \n",
      " 9   FECH_CONTAB           1242 non-null   datetime64[ns]\n",
      " 10  MON                   1242 non-null   object        \n",
      " 11  INDICADOR             1242 non-null   object        \n",
      " 12  EA_EM                 1242 non-null   float64       \n",
      " 13  FACTURADO             0 non-null      float64       \n",
      " 14  PEND_FACT             1242 non-null   float64       \n",
      " 15  PEND_FACT_SOLES       1242 non-null   float64       \n",
      " 16  ESTATUS_ACEPT         1242 non-null   object        \n",
      " 17  FECH_LIB_AF           0 non-null      float64       \n",
      " 18  DEMORA                1242 non-null   int64         \n",
      " 19  ANTIGUAMIENTO         1242 non-null   object        \n",
      " 20  RESPONSABLE           1242 non-null   object        \n",
      " 21  RESPONSABLE2          1242 non-null   object        \n",
      " 22  CE_GESTOR             1242 non-null   object        \n",
      " 23  SUB_DIRECCION         1242 non-null   object        \n",
      " 24  FECHA_REPORTE         1242 non-null   datetime64[ns]\n",
      " 25  SOLICITUD             0 non-null      float64       \n",
      " 26  ESTATUS_SOLICITUD     0 non-null      float64       \n",
      " 27  AREA_RESPONSABLE      0 non-null      float64       \n",
      " 28  RESPONSABLE_PAP       0 non-null      float64       \n",
      " 29  ACCION                0 non-null      float64       \n",
      " 30  ANTIGUAMIENTO_PAP     0 non-null      float64       \n",
      " 31  CENFILE               0 non-null      float64       \n",
      " 32  ESTADO_CENFILE        20 non-null     object        \n",
      " 33  CODIGO_SITE           20 non-null     object        \n",
      " 34  NOMBRE_SITE           20 non-null     object        \n",
      " 35  ELEMENTO_PEP          1242 non-null   object        \n",
      " 36  FECHAS COMPROMISO     1242 non-null   datetime64[ns]\n",
      " 37  MES - COMPROMISO      1242 non-null   object        \n",
      " 38  FECHA - PROY          1242 non-null   datetime64[ns]\n",
      " 39  DÍAS -2               1242 non-null   int64         \n",
      " 40  ANT-PROYECTADO        1242 non-null   object        \n",
      " 41  STATUS FINAL          1242 non-null   object        \n",
      " 42  INDICADOR2            1242 non-null   object        \n",
      " 43  ÁREA                  0 non-null      float64       \n",
      " 44  AGRUPADOR             0 non-null      float64       \n",
      " 45  RESPON                0 non-null      float64       \n",
      " 46  AVANCE AL 15.07       1242 non-null   float64       \n",
      " 47  AVANCE AL 17.07       1242 non-null   float64       \n",
      " 48  AVANCE AL 19.07       1242 non-null   float64       \n",
      " 49  AVANCE AL 24.07       1242 non-null   float64       \n",
      " 50  PENDIENTE             1242 non-null   float64       \n",
      " 51  Comentario            0 non-null      float64       \n",
      "dtypes: datetime64[ns](4), float64(21), int64(7), object(20)\n",
      "memory usage: 514.3+ KB\n"
     ]
    }
   ],
   "source": [
    "Prepa_N.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe5aeed-6480-4142-bea8-1d2c01c6f19c",
   "metadata": {},
   "source": [
    "## Cargo PAP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32501eec-de6e-49f3-bfdb-c6db1a391e8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Scripts1\\Code\\ActPEA\\archvis\\PAP\\Administrativo\\PAP_A_30.07.2024_2.xlsx\n"
     ]
    }
   ],
   "source": [
    "PAP = load_df_by_name([r'D:\\Scripts1\\Code\\ActPEA\\archvis\\PAP'],Today_D_M) #Solo cargar el primero de la fecha es aqui XD \n",
    "PAP = PAP[0]\n",
    "PAP_A = get_recent_df(r'D:\\Scripts1\\Code\\ActPEA\\archvis\\PAP\\Administrativo','Hoja2')# PAP de Admin\n",
    "\n",
    "PAP = pd.concat([PAP,PAP_A])\n",
    "#PAP = pd.read_excel(r'D:\\Scripts1\\Code\\ActPEA\\archvis\\PAP\\PAP 19.04.xlsx',sheet_name = 'Hoja2') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413da17e-c99d-4e13-81c2-644344aab162",
   "metadata": {},
   "source": [
    "# Preprocesing\n",
    "    Paso01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbc67bc-74ac-4d22-aaeb-f55dda77425c",
   "metadata": {},
   "source": [
    "## Preprosecinf of PAP & PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5cb55fb-d987-4516-94c9-5c2e18f96a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAP_f = PAP[['OC Posición','N° Sol','Estado','Nombre responsable','Id.SIte',\n",
    "             'SIte','# Días','F.Creación','Gerencia','F.Modifica']]\n",
    "##Filtro solo del norte\n",
    "PAP_f = PAP_f.dropna(subset=['Id.SIte'])\n",
    "PAP_f = PAP_f[PAP_f['# Días'] < 500]\n",
    "\n",
    "#PAP_f_N = PAP_f[PAP_f['Id.SIte'].str.startswith(('L','T','SAD','CL','CAC'))].copy()\n",
    "PAP_f_N = PAP_f.rename(columns={'N° Sol': 'PAP', #Rename\n",
    "                               'SIte': 'SITE',\n",
    "                               'Estado': 'ESTADO_PAP',\n",
    "                                '# Días': 'ANTIGUAMIENTO_PAP',\n",
    "                                'Id.SIte': 'ID Site',\n",
    "                             'Nombre responsable': 'RESPONSABLE_PAP' })\n",
    "PAP_S = Ac.split_ocs(PAP_f_N) # Spliteo OCs\n",
    "PAP_S['OC Posición'] = PAP_S['OC Posición'].astype(str)\n",
    "######################################################### PREP\n",
    "Prepa_CI = Prepa_N[Prepa_N.SUB_DIRECCION == 'CONS E IMP']\n",
    "Prepa_PR = Ac.convert_columns_to_str(Prepa_CI.copy(),['DOC_COMPRAS', 'POSIC','CONCA'])\n",
    "Prepa_PR.loc[:, \"OC Posición\"] = Prepa_PR.loc[:, \"DOC_COMPRAS\"].str.cat(Prepa_PR.loc[:, \"POSIC\"], sep= \":\")\n",
    "Monto_In = Prepa_PR[\"PEND_FACT_SOLES\"].sum() #Mont of USD \n",
    "Prepa_PR = Prepa_PR.dropna(axis=1,how='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bad12f-e192-480a-9b52-055e29412557",
   "metadata": {},
   "source": [
    "# Paso 02(Seudo-merge), act columnas \n",
    ">Añado columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36d04155-dd43-42b5-a9a1-406d35baa6a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unconverted data remains when parsing with format \"%d/%m/%Y %I:%M:%S %p\": \"AM\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m PRE_all_act \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_from_PAP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPrepa_PR\u001b[49m\u001b[43m,\u001b[49m\u001b[43mPAP_S\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#PRE_all_act = PRE_all_act[PRE_all_act['STATUS FINAL'] == 'PENDIENTE']\u001b[39;00m\n\u001b[0;32m      3\u001b[0m display(PRE_all_act\u001b[38;5;241m.\u001b[39mESTADO_PAP\u001b[38;5;241m.\u001b[39mvalue_counts(dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "Cell \u001b[1;32mIn[44], line 113\u001b[0m, in \u001b[0;36mupdate_from_PAP\u001b[1;34m(Prepa_PR, PAP_S)\u001b[0m\n\u001b[0;32m    111\u001b[0m PRE_all_act\u001b[38;5;241m.\u001b[39mdrop(PRE_all_act[duplicated_index]\u001b[38;5;241m.\u001b[39mindex, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m## dropeo las duplicadas\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Ordena el DataFrame por la columna de fechas  LA FECHA DE CREACION ME SIRVE PARA ELMINAR DUPLICADOS\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m df_duplicated[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF.Modifica\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_duplicated\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mF.Modifica\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm/\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mI:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mS \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Paso a fecha para ordenar\u001b[39;00m\n\u001b[0;32m    114\u001b[0m df_duplicated\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF.Modifica\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    115\u001b[0m df_duplicated_NR \u001b[38;5;241m=\u001b[39m df_duplicated[df_duplicated\u001b[38;5;241m.\u001b[39mESTADO_PAP \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRechazado\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msort_index(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1112\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1111\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1112\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1113\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:488\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    491\u001b[0m     arg,\n\u001b[0;32m    492\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    496\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m )\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:519\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    509\u001b[0m     arg,\n\u001b[0;32m    510\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    514\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    515\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    516\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 519\u001b[0m     result, timezones \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tz \u001b[38;5;129;01min\u001b[39;00m timezones):\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
      "File \u001b[1;32mstrptime.pyx:534\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:359\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unconverted data remains when parsing with format \"%d/%m/%Y %I:%M:%S %p\": \"AM\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "PRE_all_act = update_from_PAP(Prepa_PR,PAP_S)\n",
    "#PRE_all_act = PRE_all_act[PRE_all_act['STATUS FINAL'] == 'PENDIENTE']\n",
    "display(PRE_all_act.ESTADO_PAP.value_counts(dropna=False))\n",
    "### Mapeo Compuesto \n",
    "#Modifico el valor par adetemrina condicion\n",
    "PRE_all_act_maped = map_estados(PRE_all_act)\n",
    "a = PRE_all_act_maped.ESTADO.value_counts().reset_index()\n",
    "a.to_csv(f'D:/Prepa_N/Recuento_estados-{Today_D_M}.csv',index_label=False)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8687d401-6046-4cfc-bbc6-9d1221da7b7e",
   "metadata": {},
   "source": [
    "# 2 FILL missing values by Tablas SAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc40bce-d6ca-4e4c-baf7-8cfa2e4f9523",
   "metadata": {},
   "source": [
    "## Cargo Tabla SAP ya unida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755594cf-fc02-447b-845e-50480babbefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combinado = pd.read_csv(r'D:\\Scripts1\\Code\\ActPEA\\CODE\\Temps\\SAPCombi.csv')\n",
    "df_combinado = Ac.convert_columns_to_str(df_combinado,['OC','Pos'])\n",
    "df_combinado.loc[:, \"CONCATENADO\"] = df_combinado.loc[:, \"OC\"].str.cat(df_combinado.loc[:, \"Pos\"], sep= \"\")\n",
    "SAP_4_use = df_combinado[['CONCATENADO','PEP Desc','Fecha OC']]\n",
    "map_nameSITE = {'TJ5125-SANTIAGO DE CHUCO' : 'TJ5125-SANTIAGO_DE_CHUCO'}\n",
    "SAP_4_use.loc[:,'PEP Desc'] = SAP_4_use['PEP Desc'].replace(map_nameSITE)\n",
    "SAP_4_use = SAP_4_use.drop_duplicates()\n",
    "PRE_all_act_maped.rename(columns={'CONCA':'CONCATENADO','ID Site':'ID_SITIO'},inplace=True)\n",
    "PRE_all_act_maped = Ac.addSite(PRE_all_act_maped,SAP_4_use) # Añado sitio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a0d74-372b-4056-a16b-5b135d79d55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_ocs_sinSITE(PRE_all_act_maped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f199a3-202f-400b-b4d6-9ff2b0a5e873",
   "metadata": {},
   "source": [
    "# Agrego antiguamiento para los proyectos sin registrar\n",
    "    Calculo para todas las filas la diferencia pero solo asigno el valor al antigueamiento en las filas que cumplan la condicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdd3d71-129f-44cb-b564-571d8cc06e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_all_act_maped['Time_diff'] = datetime.date.today() - PRE_all_act_maped['FECH_CONTAB'].dt.date\n",
    "PRE_all_act_maped['Time_diff'] = PRE_all_act_maped['Time_diff'].astype(str)\n",
    "PRE_all_act_maped['ANTIGUAMIENTO_PAP'] = PRE_all_act_maped['ANTIGUAMIENTO_PAP'].astype(str)\n",
    "PRE_all_act_maped['Time_diff'] = PRE_all_act_maped['Time_diff'].str.split(' ').str[0]\n",
    "PRE_all_act_maped.loc[PRE_all_act_maped['ESTADO'] == 'Sin Registrar', 'ANTIGUAMIENTO_PAP'] = PRE_all_act_maped['Time_diff']\n",
    "## Drop usseless columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1c9e07-207d-4de2-9929-1d79d720c4ba",
   "metadata": {},
   "source": [
    "# Capa de plata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a546c6-8d70-4077-b0fd-4f21870a2fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### REcupero lista de columnas a usar\n",
    "with open(r\"D:\\Scripts1\\Code\\ActPEA\\CODE\\Temps\\mi_lista.pickle\", \"rb\") as archivo:\n",
    "    lista_recuperada = pickle.load(archivo)\n",
    "columns_E = lista_recuperada\n",
    "Prepa_silver = PRE_all_act_maped[columns_E]\n",
    "#Prepa_silver.ESTADO_CENFILE.replace(0,'No Aplica',inplace=True)\n",
    "Prepa_silver.to_csv(fr'D:\\Prepa_N\\Prepas\\Prepa_N{Today_str}.csv',index=False) # guardo historico de el de plata\n",
    "print(f'Prepa_N al {Today_str} Guardado')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f59b08-593e-47cf-874a-b00332e87ac1",
   "metadata": {},
   "source": [
    "## Añado linea Al TS \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad99c9-b0e7-4cc6-b5aa-7071c9f498e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepa_silver.columns = Prepa_silver.columns.str.strip().str.replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95a57d49-a16e-4813-b8c1-e608b17bd939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 410 entries, 6 to 723\n",
      "Data columns (total 31 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   DOC_COMPRAS           410 non-null    object        \n",
      " 1   POSIC                 410 non-null    object        \n",
      " 2   CONCATENADO           410 non-null    object        \n",
      " 3   DOCUMENTO_REFERENCIA  410 non-null    int64         \n",
      " 4   FONDO                 410 non-null    object        \n",
      " 5   TIPO_MAT              410 non-null    object        \n",
      " 6   TEXTO_BREVE           410 non-null    object        \n",
      " 7   CODPROVEEDOR          410 non-null    int64         \n",
      " 8   NOMPROVEEDOR          410 non-null    object        \n",
      " 9   FECH_CONTAB           410 non-null    datetime64[ns]\n",
      " 10  INDICADOR             410 non-null    object        \n",
      " 11  EA_EM                 410 non-null    float64       \n",
      " 12  PEND_FACT             410 non-null    float64       \n",
      " 13  PEND_FACT_SOLES       410 non-null    float64       \n",
      " 14  DEMORA                410 non-null    int64         \n",
      " 15  ANTIGUAMIENTO         410 non-null    object        \n",
      " 16  RESPONSABLE           410 non-null    object        \n",
      " 17  RESPONSABLE2          410 non-null    object        \n",
      " 18  CE_GESTOR             410 non-null    object        \n",
      " 19  SUB_DIRECCION         410 non-null    object        \n",
      " 20  FECHA_REPORTE         410 non-null    datetime64[ns]\n",
      " 21  ELEMENTO_PEP          410 non-null    object        \n",
      " 22  FECHASCOMPROMISO      410 non-null    datetime64[ns]\n",
      " 23  MES-COMPROMISO        410 non-null    object        \n",
      " 24  DÍAS-2                410 non-null    int64         \n",
      " 25  ANT-PROYECTADO        410 non-null    object        \n",
      " 26  ID_SITIO              410 non-null    object        \n",
      " 27  ANTIGUAMIENTO_PAP     410 non-null    object        \n",
      " 28  PAP                   400 non-null    float64       \n",
      " 29  SITE                  410 non-null    object        \n",
      " 30  ESTADO                410 non-null    object        \n",
      "dtypes: datetime64[ns](3), float64(4), int64(4), object(20)\n",
      "memory usage: 118.7+ KB\n"
     ]
    }
   ],
   "source": [
    "Prepa_silver.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f663ad0-f111-42cd-99d9-c4e322b305af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Como normalizo el nombre de columna ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80227ee7-8b95-4744-b571-987684986c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se añade la linea de:  30-07-2024 al TS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\C26764\\AppData\\Local\\Temp\\ipykernel_4072\\3930541988.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TIME'] = Fecha\n"
     ]
    }
   ],
   "source": [
    "# Nombre del archivo donde se almacenará la fecha\n",
    "filename = 'last_run_2.json'\n",
    "# Carga la última fecha de ejecución\n",
    "last_run_date = Ac.load_last_run_date(filename)\n",
    "# Comprueba si la celda ya se ha ejecutado hoy\n",
    "if last_run_date != datetime.datetime.now().date():\n",
    "    # Tu código aquí\n",
    "    print('Se añade la linea de: ',Today_str,'al TS')\n",
    "    ### Tener cuidado que solo se ejecuta una vez al dia\n",
    "    new_line_TS(Prepa_silver,r'\\\\LIMBIPBICOV01.claro.pe\\Red Región Norte\\DashBoardNacional\\Prepa_TS1.csv',Today_str,\n",
    "                                                           ['TIME','NOMPROVEEDOR','RESPONSABLE2','MES-COMPROMISO']) \n",
    "    # Guarda la fecha de hoy como la última fecha de ejecución\n",
    "    Ac.save_last_run_date(filename)\n",
    "else:\n",
    "    print(\"El código ya se ha ejecutado hoy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b208d53-cd59-4414-b724-e278167cf4db",
   "metadata": {},
   "source": [
    "# Capa GOLD\n",
    "--------------------------------------\n",
    "    -Calculo la instancia de tiempo, con esa etiqueta extraigo los archivos correspondientes, para mergearlos luego agruparlos y luego calcular la diferencia en base a ese temporal.\n",
    "    (provicional hasta que tenga DB de Nacionales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "823958a3-cde1-4a1c-8993-c2cf5d317328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La fecha con la se va a comparar es:  23.07\n"
     ]
    }
   ],
   "source": [
    "# Calcula la fecha de la semana pasada\n",
    "Today_date = datetime.datetime.strptime(Today_str, '%d-%m-%Y')\n",
    "semana_pasada = Today_date  - datetime.timedelta(weeks=1)\n",
    "# Conviértela a cadena de texto\n",
    "semana_pasada_str = semana_pasada.strftime('%d-%m-%Y')\n",
    "date_last_week=  semana_pasada_str[:5].replace('-','.')\n",
    "print('La fecha con la se va a comparar es: ',date_last_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6853e0-7515-4d28-861c-ab5b13affdf1",
   "metadata": {},
   "source": [
    "### Creo el Temp-past\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746cf122-282a-4e16-a8b9-53ed138fc89b",
   "metadata": {},
   "source": [
    "#### @TODO Cambiar la funcion que busca el mas antiguo a una mas robusta que busque el mas antiguo pero mas cercano a la fecha que le voy a pasar \n",
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d75f6be-641b-4c86-898f-7be844a38123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Worksheet named 'Hoja2' not found. Trying with 'Sheet1'\n",
      "-4.656612873077393e-10\n",
      "Se encuentra la columan 'STATUSFINAL' y se dropeand las filas de mas\n",
      "Se creo el df del pasado\n"
     ]
    }
   ],
   "source": [
    "df = load_df_by_name([r'\\\\LIMBIPBICOV01.claro.pe\\Red Región Norte\\Resultados_prepa',r'D:\\Scripts1\\Code\\ActPEA\\archvis\\PAP'],date_last_week)\n",
    "#EL INDEX1 ES EL PAP, EL 0 ES EL PREPA\n",
    "df_silver_past = Merge_data(df[1],df[0])\n",
    "print('Se creo el df del pasado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb66778c-a970-45f6-99ed-495f6634fc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Prepa_N\\Prepas\\Prepa_N30-07-2024.csv\n"
     ]
    }
   ],
   "source": [
    "Last_silver = get_recent_df(r'D:\\Prepa_N\\Prepas',extension=\".csv\") # en caso quiera cargar el df que ya hize para compararlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3526e72c-a4ad-4c11-bec0-b893a063081c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 410 entries, 0 to 409\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Orden De Compra       410 non-null    int64  \n",
      " 1   Posición              410 non-null    int64  \n",
      " 2   Documento Referencia  410 non-null    int64  \n",
      " 3   Descripción           410 non-null    object \n",
      " 4   Codproveedor          410 non-null    int64  \n",
      " 5   Contratista           410 non-null    object \n",
      " 6   Fecha Contabilidad    410 non-null    object \n",
      " 7   Pendiente En Soles    410 non-null    float64\n",
      " 8   Demora                410 non-null    int64  \n",
      " 9   Antiguamiento         410 non-null    object \n",
      " 10  Responsable2          410 non-null    object \n",
      " 11  Ce Gestor             410 non-null    object \n",
      " 12  Fecha Reporte         410 non-null    object \n",
      " 13  Fechas Compromiso     410 non-null    object \n",
      " 14  Mes De Compromiso     410 non-null    object \n",
      " 15  Id Sitio              410 non-null    object \n",
      " 16  Antiguamiento Pap     410 non-null    float64\n",
      " 17  N° Pap                400 non-null    float64\n",
      " 18  Site                  410 non-null    object \n",
      " 19  Estado                410 non-null    object \n",
      " 20  Diferencia En Soles   410 non-null    float64\n",
      "dtypes: float64(4), int64(5), object(12)\n",
      "memory usage: 67.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF GOLD Creado y guardado\n"
     ]
    }
   ],
   "source": [
    "df_gold = calc_diff(Last_silver,df_silver_past,['RESPONSABLE2','NOMPROVEEDOR']) ##Calculo diff con esta agrupacion\n",
    "df_gold['DIFERENCIA EN SOLES'] = df_gold['DIFERENCIA EN SOLES'].transform(lambda x: x / df_gold['DIFERENCIA EN SOLES'].value_counts()[x] if pd.notnull(x) else x) #Spliteo montos en filas\n",
    "df_gold_Formated = formated2bi(df_gold) #Formateo\n",
    "display(df_gold_Formated.info())\n",
    "df_gold_Formated.to_csv(r'\\\\LIMBIPBICOV01.claro.pe\\Red Región Norte\\DashBoardNacional\\PrepasivoNacional.csv',index= False)\n",
    "print('DF GOLD Creado y guardado')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e23760-4555-4890-b622-bd6af2dcb159",
   "metadata": {},
   "source": [
    "# PAra crear un modelo estrella:\n",
    "-Del GOLD\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47754f67-f1a0-46a5-9ca0-81e37b8f877f",
   "metadata": {},
   "source": [
    "### Cargo la data necesaria para ello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "666f52b8-a67e-4bf9-86e4-cf3ea618d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepa_N =  pd.read_csv(r'\\\\LIMBIPBICOV01.claro.pe\\Red Región Norte\\DashBoardNacional\\PrepasivoNacional.csv') \n",
    "Prepa_N.Estado = Prepa_N.Estado.str.title()\n",
    "Estado_dim = pd.read_csv(r'D:\\Scripts1\\Code\\ActPEA\\CODE\\Temps\\estados.txt',delim_whitespace=True)  # Cargo los estados y su orden \n",
    "Estado_dim.drop(columns=['Índice'],inplace=True)\n",
    "Estado_dim.Estado = Estado_dim.Estado.str.replace('_',' ')\n",
    "Estado_dim.Estado = Estado_dim.Estado.str.title()\n",
    "Estado_dim.Estado = Estado_dim.Estado.str.strip()\n",
    "hechos = ['Orden De Compra','Posición','Documento Referencia','Descripción',\n",
    "          'Fecha Contabilidad','Pendiente En Soles','Demora','Antiguamiento','Ce Gestor'\n",
    "          ,'Id Sitio','Antiguamiento Pap','N° Pap','Site','Diferencia En Soles']\n",
    "Prepa_N['Mes De Compromiso'] = Prepa_N['Mes De Compromiso'].replace('Setiembre','Septiembre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a00ee03-c8bd-453b-93d8-7964ad0cee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Estado_dim.Estado = Estado_dim.Estado.replace('Julio Arceniega','Julio Arciniega')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62c827b7-b75f-40ef-ab41-4cfa28ceaf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "Contrata_dim = Prepa_N[['Codproveedor','Contratista']].drop_duplicates().reset_index(drop=True)\n",
    "Responsable_dim = Prepa_N['Responsable2'].drop_duplicates().reset_index(drop=True)\n",
    "Mes_dim = Prepa_N['Mes De Compromiso'].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "#Agrego index a cada dimension\n",
    "Contrata_dim = Contrata_dim.reset_index().rename(columns={'index': 'Contrata_id'})#Este es perma\n",
    "Responsable_dim = Responsable_dim.reset_index().rename(columns={'index': 'Responsable_id'})#Este es perma\n",
    "Mes_dim = Mes_dim.reset_index().rename(columns={'index': 'Mes_id'})# Este aun falta conca\n",
    "Estado_dim = Estado_dim.reset_index().rename(columns={'index': 'Estado_id'})# Este es perma\n",
    "Estado_dim.Estado = Estado_dim.Estado.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a184a8d4-61df-40c2-aeac-cf8e1bf10722",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 410 entries, 0 to 409\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Orden De Compra       410 non-null    int64  \n",
      " 1   Posición              410 non-null    int64  \n",
      " 2   Documento Referencia  410 non-null    int64  \n",
      " 3   Descripción           410 non-null    object \n",
      " 4   Codproveedor          410 non-null    int64  \n",
      " 5   Contratista           410 non-null    object \n",
      " 6   Fecha Contabilidad    410 non-null    object \n",
      " 7   Pendiente En Soles    410 non-null    float64\n",
      " 8   Demora                410 non-null    int64  \n",
      " 9   Antiguamiento         410 non-null    object \n",
      " 10  Responsable2          410 non-null    object \n",
      " 11  Ce Gestor             410 non-null    object \n",
      " 12  Fecha Reporte         410 non-null    object \n",
      " 13  Fechas Compromiso     410 non-null    object \n",
      " 14  Mes De Compromiso     410 non-null    object \n",
      " 15  Id Sitio              410 non-null    object \n",
      " 16  Antiguamiento Pap     410 non-null    float64\n",
      " 17  N° Pap                400 non-null    float64\n",
      " 18  Site                  410 non-null    object \n",
      " 19  Estado                410 non-null    object \n",
      " 20  Diferencia En Soles   410 non-null    float64\n",
      "dtypes: float64(4), int64(5), object(12)\n",
      "memory usage: 67.4+ KB\n"
     ]
    }
   ],
   "source": [
    "Prepa_N.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16a3b3e3-509d-403a-a15e-943d14f7feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimension estado \n",
    "Estado_dim1 = Prepa_N['Estado'].drop_duplicates().reset_index(drop=True)\n",
    "Estado_dim1 = Estado_dim1.reset_index().rename(columns={'index': 'Estado_id'})\n",
    "Estado_dim1_T = pd.concat([Estado_dim,Estado_dim1])\n",
    "Estado_dim1_T = Estado_dim1_T.drop_duplicates(subset='Estado')\n",
    "Estado_dim1_T['Estado_id'] = range(0,len(Estado_dim1_T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08eb6b6-b7f0-4128-997b-3280e2d25a19",
   "metadata": {},
   "source": [
    "## Del TIME SERIES \n",
    "> Normalizar todo, concat, unique, merge y export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78c41f22-cc70-4d01-a8c7-bcab2d70cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "TS = pd.read_csv(r'\\\\LIMBIPBICOV01.claro.pe\\Red Región Norte\\DashBoardNacional\\Prepa_TS1.csv')\n",
    "TS.rename(columns={'NOMPROVEEDOR':'Contratista',\n",
    "                  'RESPONSABLE2':'Responsable2',\n",
    "                  'MES-COMPROMISO':'Mes De Compromiso'},inplace=True)\n",
    "TS.Contratista = TS.Contratista.str.title()\n",
    "hechos2 = ['PEND_FACT_SOLES']\n",
    "TS['Mes De Compromiso'] = TS['Mes De Compromiso'].replace('Setiembre','Septiembre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "910ada90-c671-4f1a-a5e4-08467186756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimension Contrat\n",
    "Contrata_dim1 = TS['Contratista'].drop_duplicates().reset_index(drop=True)\n",
    "Contrata_dim1 = Contrata_dim1.reset_index().rename(columns={'index': 'Contrata_id'})\n",
    "Contrata_dim_T = pd.concat([Contrata_dim1,Contrata_dim])\n",
    "Contrata_dim_T = Contrata_dim_T['Contratista'].drop_duplicates().reset_index(drop=True)\n",
    "Contrata_dim_T = Contrata_dim_T.reset_index().rename(columns={'index': 'Contrata_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60dae3c5-6a6f-4a08-afc1-113bd4af0d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es_ES.UTF-8'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2cc803f4-273a-4019-976b-812124a288af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimension MES\n",
    "Mes_dim1 = TS['Mes De Compromiso'].drop_duplicates().reset_index(drop=True)\n",
    "Mes_dim1 = Mes_dim1.reset_index().rename(columns={'index': 'Mes_id'})\n",
    "Mes_dim_T = pd.concat([Mes_dim1,Mes_dim])\n",
    "Mes_dim_T = Mes_dim_T['Mes De Compromiso'].drop_duplicates().reset_index(drop=True)\n",
    "Mes_dim_T = Mes_dim_T.reset_index().rename(columns={'index': 'Mes_id'})\n",
    "Mes_dim_T.loc[:,'Mes De Compromiso'] = Mes_dim_T.loc[:,'Mes De Compromiso'].replace('Setiembre','Septiembre')\n",
    "Mes_dim_T = Mes_dim_T[~Mes_dim_T['Mes De Compromiso'].isin(['Nuevas EA','Pendiente'])].copy()\n",
    "\n",
    "Mes_dim_T.loc[:,'Mes De Compromiso'] = Mes_dim_T['Mes De Compromiso'].str.lower()\n",
    "Mes_dim_T.loc[:,'Numero Mes'] = Mes_dim_T['Mes De Compromiso'].apply(lambda x: list(calendar.month_name).index(x))\n",
    "Mes_dim_T.loc[:,'Mes De Compromiso'] = Mes_dim_T['Mes De Compromiso'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a19520a6-433b-4be3-bf83-4a4446394fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mes_id</th>\n",
       "      <th>Mes De Compromiso</th>\n",
       "      <th>Numero Mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Marzo</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Febrero</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Abril</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Mayo</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Enero</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Agosto</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Julio</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Junio</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Octubre</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Septiembre</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Diciembre</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Noviembre</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mes_id Mes De Compromiso  Numero Mes\n",
       "0        0             Marzo           3\n",
       "1        1           Febrero           2\n",
       "2        2             Abril           4\n",
       "3        3              Mayo           5\n",
       "4        4             Enero           1\n",
       "5        5            Agosto           8\n",
       "6        6             Julio           7\n",
       "7        7             Junio           6\n",
       "10      10           Octubre          10\n",
       "11      11        Septiembre           9\n",
       "12      12         Diciembre          12\n",
       "13      13         Noviembre          11"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mes_dim_T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e7922a-7b5e-4253-ae23-7cd74bfd9947",
   "metadata": {},
   "source": [
    "### Creo tabla calendar\n",
    " - 1. Agarrro las columnas de fehcas de las 2 tablas, las concateno, limpio duplicados, ordeno.\n",
    "   2. Maximo y minimo en variables\n",
    "   3. Con eso creo mi tabla calendar y sus demas columnas\n",
    "   4. merge para asignar el id de cada fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb285c17-4f01-4eef-8371-23d1afa14943",
   "metadata": {},
   "outputs": [],
   "source": [
    "dias_abreviados = ['Lun', 'Mar', 'Mie', 'Jue', 'Vie', 'Sab', 'Dom']\n",
    "\n",
    "# Función para formatear la fecha\n",
    "def formatear_fecha(fecha):\n",
    "    dia_abreviado = dias_abreviados[fecha.weekday()]\n",
    "    return f\"{dia_abreviado},{fecha.strftime('%d-%m-%y')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "127a65b8-1530-4bf5-b407-2bb2d6cc34a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Time = pd.concat([Prepa_N['Fechas Compromiso'],TS['TIME']])\n",
    "Time_df = Time.to_frame()\n",
    "Time_df.columns = ['Time']\n",
    "Time_df = Time_df.drop_duplicates()\n",
    "locale.setlocale(locale.LC_ALL, '')\n",
    "# Convertir la columna 'Time' a datetime, forzando errores a NaT\n",
    "Time_df['Time'] = pd.to_datetime(Time_df['Time'], errors='coerce')\n",
    "# Eliminar filas con NaT en la columna 'Time'\n",
    "Time_df = Time_df.dropna(subset=['Time'])\n",
    "# Ordenar el DataFrame por la columna 'Time'\n",
    "Time_df = Time_df.sort_values(by='Time', ascending=True).reset_index(drop=True)\n",
    "# Define las fechas de inicio y fin\n",
    "start_date = Time_df['Time'].min()\n",
    "end_date = Time_df['Time'].max()\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "# Crea un rango de fechas\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "# Crea un DataFrame a partir del rango de fechas\n",
    "Calendar_df = pd.DataFrame(date_range, columns=['Date'])\n",
    "\n",
    "# Extrae el año, mes, día, semana, día de la semana, trimestre de la fecha\n",
    "Calendar_df['Year'] = Calendar_df['Date'].dt.year\n",
    "Calendar_df['Month_id'] = Calendar_df['Date'].dt.month\n",
    "Calendar_df['Day'] = Calendar_df['Date'].dt.day\n",
    "Calendar_df.rename(columns={'Date':'TIME'},inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')  # Ajusta según tu sistema operativo\n",
    "Calendar_df['Date-format'] = Calendar_df['TIME'].apply(formatear_fecha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7223b9ca-457d-4826-95f8-e3a1f3066114",
   "metadata": {},
   "outputs": [],
   "source": [
    "Calendar_df = Calendar_df.reset_index().rename(columns={'index': 'Date_id'})# Este es perma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f13056cd-0965-4fcb-b5d0-8e1c1eeba683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_id</th>\n",
       "      <th>TIME</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date-format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Vie,01-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-03-02</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Sab,02-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-03</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Dom,03-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-03-04</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Lun,04-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-03-05</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Mar,05-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>300</td>\n",
       "      <td>2024-12-26</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>Jue,26-12-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>301</td>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>Vie,27-12-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>302</td>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>Sab,28-12-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>303</td>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>Dom,29-12-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>304</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>Lun,30-12-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date_id       TIME  Year  Month_id  Day   Date-format\n",
       "0          0 2024-03-01  2024         3    1  Vie,01-03-24\n",
       "1          1 2024-03-02  2024         3    2  Sab,02-03-24\n",
       "2          2 2024-03-03  2024         3    3  Dom,03-03-24\n",
       "3          3 2024-03-04  2024         3    4  Lun,04-03-24\n",
       "4          4 2024-03-05  2024         3    5  Mar,05-03-24\n",
       "..       ...        ...   ...       ...  ...           ...\n",
       "300      300 2024-12-26  2024        12   26  Jue,26-12-24\n",
       "301      301 2024-12-27  2024        12   27  Vie,27-12-24\n",
       "302      302 2024-12-28  2024        12   28  Sab,28-12-24\n",
       "303      303 2024-12-29  2024        12   29  Dom,29-12-24\n",
       "304      304 2024-12-30  2024        12   30  Lun,30-12-24\n",
       "\n",
       "[305 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Calendar_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c392ef-0ca7-4311-9dd7-a962f2738b8b",
   "metadata": {},
   "source": [
    "## Relaciono tablas y Creo tabla de Hechos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbf0bae3-71c5-44dc-977b-217a3edf0d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una tabla de hechos\n",
    "hechos_df = Prepa_N.copy()\n",
    "hechos_df = pd.merge(hechos_df, Contrata_dim_T, on='Contratista',how='left')\n",
    "hechos_df = pd.merge(hechos_df, Responsable_dim, on='Responsable2',how='left')\n",
    "hechos_df = pd.merge(hechos_df, Mes_dim_T, on='Mes De Compromiso',how='left')\n",
    "hechos_df = pd.merge(hechos_df, Estado_dim1_T, on='Estado',how='left')\n",
    "\n",
    "fact_2bi = hechos_df[['Contrata_id', 'Responsable_id','Mes_id','Estado_id'] + hechos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35126753-df97-4b3d-bf78-93bf0d606d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una tabla de hechos\n",
    "hechos2_df = TS.copy()\n",
    "hechos2_df['TIME'] = pd.to_datetime(hechos2_df['TIME'])\n",
    "hechos2_df = pd.merge(hechos2_df, Contrata_dim_T, on='Contratista',how='left')\n",
    "hechos2_df = pd.merge(hechos2_df, Responsable_dim, on='Responsable2',how='left')\n",
    "hechos2_df = pd.merge(hechos2_df, Mes_dim_T, on='Mes De Compromiso',how='left')\n",
    "hechos2_df = pd.merge(hechos2_df, Calendar_df[['Date_id','TIME']], on='TIME',how='left')\n",
    "\n",
    "#hechos2_df = pd.merge(hechos2_df, Contrata_dim, on='Codproveedor',how='left')\n",
    "\n",
    "\n",
    "facTS_2bi = hechos2_df[['Responsable_id','Mes_id','Contrata_id','Date_id'] + hechos2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bfdb73f4-f6ce-424a-a12e-8299e2c0cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estaticas\n",
    "Contrata_dim_T.to_csv(r'\\\\LIMBIPBICOV01.claro.pe\\Red Región Norte\\DashBoardNacional\\DATA\\Contrata_dim.csv',index=False)\n",
    "Responsable_dim.to_csv(r'\\\\LIMBIPBICOV01.claro.pe\\Red Región Norte\\DashBoardNacional\\DATA\\Responsable_dim.csv',index=False)\n",
    "Estado_dim1_T.to_csv(r'\\\\LIMBIPBICOV01.claro.pe\\Red Región Norte\\DashBoardNacional\\DATA\\Estado_dim.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14334c8b-7310-43e5-9b54-96e1654f028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Casi dinamicas\n",
    "Mes_dim_T.to_csv(r'\\\\LIMBIPBICOV01.claro.pe\\Red Región Norte\\DashBoardNacional\\DATA\\Mes_dim.csv',index=False)\n",
    "Calendar_df.to_csv(r'\\\\LIMBIPBICOV01.claro.pe\\Red Región Norte\\DashBoardNacional\\DATA\\Calendar_table.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dfb0e478-d1ef-49b0-aa29-d55d6b31eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dinamicas\n",
    "facTS_2bi.to_csv( r'\\\\LIMBIPBICOV01.claro.pe\\Red Región Norte\\DashBoardNacional\\DATA\\TS_N_fact.csv',index=False)\n",
    "fact_2bi.to_csv(r'\\\\LIMBIPBICOV01.claro.pe\\Red Región Norte\\DashBoardNacional\\DATA\\hechos_df.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95f93980-dc44-4de6-b93f-ef05021184a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_id</th>\n",
       "      <th>TIME</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date-format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Vie,01-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-03-02</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Sab,02-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-03</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Dom,03-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-03-04</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Lun,04-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-03-05</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Mar,05-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>300</td>\n",
       "      <td>2024-12-26</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>Jue,26-12-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>301</td>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>Vie,27-12-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>302</td>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>Sab,28-12-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>303</td>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>Dom,29-12-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>304</td>\n",
       "      <td>2024-12-30</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>Lun,30-12-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date_id       TIME  Year  Month_id  Day   Date-format\n",
       "0          0 2024-03-01  2024         3    1  Vie,01-03-24\n",
       "1          1 2024-03-02  2024         3    2  Sab,02-03-24\n",
       "2          2 2024-03-03  2024         3    3  Dom,03-03-24\n",
       "3          3 2024-03-04  2024         3    4  Lun,04-03-24\n",
       "4          4 2024-03-05  2024         3    5  Mar,05-03-24\n",
       "..       ...        ...   ...       ...  ...           ...\n",
       "300      300 2024-12-26  2024        12   26  Jue,26-12-24\n",
       "301      301 2024-12-27  2024        12   27  Vie,27-12-24\n",
       "302      302 2024-12-28  2024        12   28  Sab,28-12-24\n",
       "303      303 2024-12-29  2024        12   29  Dom,29-12-24\n",
       "304      304 2024-12-30  2024        12   30  Lun,30-12-24\n",
       "\n",
       "[305 rows x 6 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Calendar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06120e59-fa72-43c1-9881-f81799d46a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ee592-f3da-48ea-8fac-570dfe16617f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
